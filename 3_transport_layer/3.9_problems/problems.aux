\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Problems}{87}{subsection.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.1}Suppose Client A requests a web page from Server S through HTTP and its socket is associated with port 33000 (P1)}{87}{subsubsection.3.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.2}Consider Figure 3.5. (P2)}{87}{subsubsection.3.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.3}UDP and TCP use 1s complement for their checksums. Suppose you have the following three 16 bit words: 0101001101100110; 0111010010110100; \\ 0000110111000001. What is the 1s complement of the sum of these words? Show all work. Why is it that UDP offers a checksum? With the 1's complement scheme, how does the receiver detect errors? Describe how a single bit flip can be detected. (P3)}{88}{subsubsection.3.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.4}Assume that a host receives a UDP segment with 01011101 11110010 (we separated the values of each byte with a space for clarity) as the checksum. The host adds the 16-bit words over all necessary fields excluding the check-sum and obtains the value 00110010 00001101. Is the segment considered correctly received or not? What does the receiver do? (P4)}{88}{subsubsection.3.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.5}Suppose that the UDP receiver computes the Internet checksum for the received UDP segment and finds that it matches the value carried in the checksum field. Can the receiver be absolutely certain that no bit errors have occurred? Explain. (P5)}{88}{subsubsection.3.9.5}\protected@file@percent }
\citation{kr}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.6}Consider our motivation for correcting protocol \texttt  {rdt2.1.} Show that the receiver, shown in Figure 3.60, when operating with the sender shown in Figure 3.11, can lead the sender and receiver to enter into a deadlock state, where each is waiting for an event that will never occur. (P6)}{89}{subsubsection.3.9.6}\protected@file@percent }
\newlabel{sec:kr_3.9.6}{{3.9.6}{89}{Consider our motivation for correcting protocol \texttt {rdt2.1.} Show that the receiver, shown in Figure 3.60, when operating with the sender shown in Figure 3.11, can lead the sender and receiver to enter into a deadlock state, where each is waiting for an event that will never occur. (P6)}{subsubsection.3.9.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.7}In protocol \texttt  {rdt3.0}, the ACK packets flowing from the receiver to the sender do not have sequence numbers (although they do have an ACK field that contains the sequence number of the packet they are acknowledging). Why is it that our ACK packets do not require sequence numbers? (P7)}{89}{subsubsection.3.9.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.8}Draw the FSM for the receiver side of protocol \texttt  {rdt3.0}. (P8)}{89}{subsubsection.3.9.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.9}Give a trace of the operation of protocol \texttt  {rdt3.0} when data packets and acknowledgment packets are garbled. Your trace should be similar to that used in Figure 3.16. (P9)}{89}{subsubsection.3.9.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.10}Consider a channel that can lose packets but has a maximum delay that is known. Modify protocol \texttt  {rdt2.1} to include sender timeout and retransmit. Informally argue why your protocol can communicate correctly over this channel. (P10)}{89}{subsubsection.3.9.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.11}Consider the \texttt  {rdt2.2} receiver in Figure 3.14, and the creation of a new packet in the self-transition (i.e., the transition from the state back to itself) in the Wait-for-0-from-below and the Wait-for-1-from-below states: \\ \texttt  {sndpkt=make\_pkt(ACK,1,checksum)} and \texttt  {sndpkt=make\_pkt(ACK,0,checksum)}. Would the protocol work correctly if this action were removed from the self-transition in the Wait-for-1-from-below state? Justify your answer. What if this event were removed from the self-transition in the Wait-for-0-from-below state? [Hint: In this latter case, consider what would happen if the first sender-to-receiver packet were corrupted.] (P11)}{90}{subsubsection.3.9.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.12}The sender side of \texttt  {rdt3.0} simply ignores (that is, takes no action on) all received packets that are either in error or have the wrong value in the acknum field of an acknowledgment packet. Suppose that in such circumstances, \texttt  {rdt3.0} were simply to retransmit the current data packet. Would the protocol still work? (Hint: Consider what would happen if there were only bit errors; there are no packet losses but premature timeouts can occur. Consider how many times the nth packet is sent, in the limit as n approaches infinity.) (P12)}{90}{subsubsection.3.9.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.13}Assume Host A is streaming a video from Server B using UDP. Also assume that the network suddenly becomes very congested while Host A is seeing the video. Is there any way to handle this situation with UDP? What about with TCP? Is there any other option? (P13)}{90}{subsubsection.3.9.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.14}Consider a stop-and-wait data-transfer protocol that provides error checking and retransmissions but uses only negative acknowledgments. Assume that negative acknowledgments are never corrupted. Would such a protocol work over a channel with bit errors? What about over a lossy channel with bit errors? (P14)}{91}{subsubsection.3.9.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.15}Consider the cross-country example shown in Figure 3.17, with a 10 Gbps link. How big would the window size have to be for the channel utilization to be greater than 98 percent? Suppose that the size of a packet is 1,500 bytes, including header fields and data. (P15)}{91}{subsubsection.3.9.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.16}Suppose an application uses \texttt  {rdt 3.0} as its transport layer protocol. As the stop-and-wait protocol has very low channel utilization (shown in the cross-country example), the designers of this application let the receiver keep sending back a number (more than two) of alternating ACK 0 and ACK 1 even if the corresponding data have not arrived at the receiver. Would this application design increase the channel utilization? Why? Are there any potential problems with this approach? Explain. (P16)}{91}{subsubsection.3.9.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.17}Consider two network entities, A and B, which are connected by a perfect bi-directional channel (i.e., any message sent will be received correctly; the channel will not corrupt, lose, or re-order packets). A and B are to deliver data messages to each other in an alternating manner: First, A must deliver a message to B, then B must deliver a message to A, then A must deliver a message to B and so on. If an entity is in a state where it should not attempt to deliver a message to the other side, and there is an event like \texttt  {rdt\_send(data)} call from above that attempts to pass data down for transmission to the other side, this call from above can simply be ignored with a call to \texttt  {rdt\_unable\_to\_send(data)}, which informs the higher layer that it is currently not able to send data. [Note: This simplifying assumption is made so you don't have to worry about buffering data.] Draw a FSM specification for this protocol (one FSM for A, and one FSM for B!). Note that you do not have to worry about a reliability mechanism here; the main point of this question is to create a FSM specification that reflects the synchronized behavior of the two entities. You should use the following events and actions that have the same meaning as protocol \texttt  {rdt1.0} in Figure 3.9: \texttt  {rdt\_send(data)}, \texttt  {packet = make\_pkt(data)}, \texttt  {udt\_send(packet)}, \texttt  {rdt\_rcv(packet)}, \texttt  {extract (packet,data)}, \texttt  {deliver\_data(data)}. Make sure your protocol reflects the strict alternation of sending between A and B. Also, make sure to indicate the initial states for A and B in your FSM descriptions. (P17)}{92}{subsubsection.3.9.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.18}In the generic SR protocol that we studied in Section 3.4.4, the sender transmits a message as soon as it is available (if it is in the window) without waiting for an acknowledgment. Suppose now that we want an SR protocol that sends messages two at a time. That is, the sender will send a pair of messages and will send the next pair of messages only when it knows that both messages in the first pair have been received correctly. Suppose that the channel may lose messages but will not corrupt or reorder messages. Design an error-control protocol for the unidirectional reliable transfer of messages. Give an FSM description of the sender and receiver. Describe the format of the packets sent between sender and receiver, and vice versa. If you use any procedure calls other than those in Section 3.4 (for example, \texttt  {udt\_send()}, \texttt  {start\_timer()}, \texttt  {rdt\_rcv()}, and so on), clearly state their actions. Give an example (a timeline trace of sender and receiver) showing how your protocol recovers from a lost packet. (P18)}{93}{subsubsection.3.9.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.19}Suppose Host A and Host B use a GBN protocol with window size $N = 3$ and a long-enough range of sequence numbers. Assume Host A sends six application messages to Host B and that all messages are correctly received, except for the first acknowledgment and the fifth data segment. Draw a timing diagram (similar to Figure 3.22), showing the data segments and the acknowledgments sent along with the corresponding sequence and acknowledge numbers, respectively. (P19)}{96}{subsubsection.3.9.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.20}Consider a scenario in which Host A and Host B want to send messages to Host C. Hosts A and C are connected by a channel that can lose and corrupt (but not reorder) messages. Hosts B and C are connected by another channel (independent of the channel connecting A and C) with the same properties. The transport layer at Host C should alternate in delivering messages from A and B to the layer above (that is, it should first deliver the data from a packet from A, then the data from a packet from B, and so on). Design a stop-and-wait-like error-control protocol for reliably transferring packets from A and B to C, with alternating delivery at C as described above. Give FSM descriptions of A and C. (Hint: The FSM for B should be essentially the same as for A.) Also, give a description of the packet format(s) used. (P20)}{97}{subsubsection.3.9.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.21}Suppose we have two network entities, A and B. B has a supply of data messages that will be sent to A according to the following conventions. When A gets a request from the layer above to get the next data (D) message from B, A must send a request (R) message to B on the A-to-B channel. Only when B receives an R message can it send a data (D) message back to A on the B-to-A channel. A should deliver exactly one copy of each D message to the layer above. R messages can be lost (but not corrupted) in the A-to-B channel; D messages, once sent, are always delivered correctly. The delay along both channels is unknown and variable. Design (give an FSM description of) a protocol that incorporates the appropriate mechanisms to compensate for the loss-prone A-to-B channel and implements message passing to the layer above at entity A, as discussed above. Use only those mechanisms that are absolutely necessary. (21)}{98}{subsubsection.3.9.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.22}Consider the GBN protocol with a sender window size of 4 and a sequence number range of 1,024. Suppose that at time $t$, the next in-order packet that the receiver is expecting has a sequence number of $k$. Assume that the medium does not reorder messages. Answer the following questions: (P22)}{99}{subsubsection.3.9.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.23}Give one example where buffering out-of-order segments would significantly improve the throughput of a GBN protocol. (P23)}{99}{subsubsection.3.9.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.24}Consider a scenario where the three hosts A, B, and C are connected as a ring: A to B, B to C, and C to A. Assume that A and C run protocol \texttt  {rdt3.0}, whereas B simply relays all messages received from A to C. (P24)}{99}{subsubsection.3.9.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.25}We have said that an application may choose UDP for a transport protocol because UDP offers finer application control (than TCP) of what data is sent in a segment and when. (P25)}{100}{subsubsection.3.9.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.26}Consider transferring an enormous file of $L$ bytes from Host A to Host B. Assume an MSS of 536 bytes. (P26)}{100}{subsubsection.3.9.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.27}Host A and B are communicating over a TCP connection following RFC 5681. Host B has already received from A all bytes up through byte 96. Suppose Host A then sends two segments to Host B back-to-back. The first and the second segments contain 40 and 80 bytes of data, respectively. In the first segment, the sequence number is 97, the source port number is 302, and the destination port number is 80. Host B sends an acknowledgment whenever it receives a segment from Host A. (P27)}{100}{subsubsection.3.9.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.28}Host A and B are directly connected with a 10 Gbps link. There is one TCP connection between the two hosts, and Host A is sending to Host B an enormous file over this connection. Host A can send its application data into its TCP socket at a rate as high as 1 Gbps, but Host B can read out of its TCP receive buffer at a maximum rate of 600 Mbps. Describe the effect of TCP flow control. (P28)}{101}{subsubsection.3.9.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.29}SYN cookies were discussed in Section 3.5.6. (P29)}{101}{subsubsection.3.9.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.30}Consider the network shown in Scenario 2 in Section 3.6.1. Suppose both sending hosts A and B have some fixed timeout values. (P30)}{102}{subsubsection.3.9.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.31}Suppose that the five measured \texttt  {SampleRTT} values (see Section 3.5.3) are 112 ms, 140 ms, 110 ms, 90 ms, and 90 ms. Compute the \texttt  {EstimatedRTT} after each of these \texttt  {SampleRTT} values is obtained, using a value of $\alpha = 0.125$ and assuming that the value of \texttt  {EstimatedRTT} was 120 ms just before the first of these five samples were obtained. Compute also the \texttt  {DevRTT} after each sample is obtained, assuming a value of $\beta = 0.25$ and assuming the value of \texttt  {DevRTT} was 6 ms just before the first of these five samples was obtained. Finally, compute the TCP \texttt  {TimeoutInterval} after each of these samples is obtained. (P31)}{102}{subsubsection.3.9.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.32}Consider the TCP procedure for estimating RTT. Suppose that $\alpha = 0.1$. Let $\texttt  {SampleRTT}_1$ be the most recent sample RTT, let $\texttt  {SampleRTT}_2$ be the next most recent sample RTT, and so on. (P32)}{104}{subsubsection.3.9.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.33}In Section 3.5.3, we discussed TCP's estimation of RTT. Why do you think TCP avoids measuring the \texttt  {SampleRTT} for retransmitted segments? (P33)}{105}{subsubsection.3.9.33}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.34}What is the relationship between the variable \texttt  {SendBase} in Section 3.5.4 and the variable \texttt  {LastByteRcvd} in Section 3.5.5? (P34)}{105}{subsubsection.3.9.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.35}What is the relationship between the variable \texttt  {LastByteRcvd} in Section 3.5.5 and the variable $y$ in Section 3.5.4? (P35)}{105}{subsubsection.3.9.35}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.36}In Section 3.5.4, we saw that TCP waits until it has received three duplicate ACKs before performing a fast retransmit. Why do you think the TCP designers chose not to perform a fast retransmit after the first duplicate ACK for a segment is received? (P36)}{105}{subsubsection.3.9.36}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.37}Compare GBN, SR, and TCP (no delayed ACK). Assume that the timeout values for all three protocols are sufficiently long such that five consecutive data segments and their corresponding ACKs can be received (if not lost in the channel) by the receiving host (Host B) and the sending host (Host A) respectively. Suppose Host A sends five data segments to Host B, and the second segment (sent from A) is lost. In the end, all five data segments have been correctly received by Host B. (P37)}{106}{subsubsection.3.9.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.38}In our description of TCP in Figure 3.53, the value of the threshold, \texttt  {ssthresh}, is set as \texttt  {ssthresh=cwnd/} in several places and \texttt  {ssthresh} value is referred to as being set to half the window size when a loss event occurred. Must the rate at which the sender is sending when the loss event occurred be approximately equal to \texttt  {cwnd} segments per RTT? Explain your answer. If your answer is no, can you suggest a different manner in which \texttt  {ssthresh} should be set? (P38)}{106}{subsubsection.3.9.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.39}Consider Figure 3.46(b). If $\lambda _\text  {in}'$ increases beyond $R/2$, can $\lambda _\text  {out}$ increase beyond $R/3$? Explain. Now consider Figure 3.46(c). If $\lambda _{in}'$ increases beyond $R/2$, can $\lambda _\text  {out}$ increase beyond $R/4$ under the assumption that a packet will be forwarded twice on average from the router to the receiver? Explain. (P39)}{107}{subsubsection.3.9.39}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.40}Consider Figure 3.61. Assuming TCP Reno is the protocol experiencing the behavior shown above, answer the following questions. In all cases, you should provide a short discussion justifying your answer. (P40)}{107}{subsubsection.3.9.40}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.41}Refer to Figure 3.57, which illustrates the convergence of TCP's AIMD algorithm. Suppose that instead of a multiplicative decrease, TCP decreased the window size by a constant amount. Would the resulting AIAD algorithm converge to an equal share algorithm? Justify your answer using a diagram similar to Figure 3.57. (P41)}{108}{subsubsection.3.9.41}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.42}In Section 3.5.4, we discussed the doubling of the timeout interval after a timeout event. This mechanism is a form of congestion control. Why does TCP need a window-based congestion-control mechanism (as studied in Section 3.7) in addition to this doubling-timeout-interval mechanism? (P42)}{109}{subsubsection.3.9.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.43}Host A is sending an enormous file to Host B over a TCP connection. Over this connection there is never any packet loss and the timers never expire. Denote the transmission rate of the link connecting Host A to the Internet by $R$ bps. Suppose that the process in Host A is capable of sending data into its TCP socket at a rate $S$ bps, where $S = 10 \cdot R$. Further suppose that the TCP receive buffer is large enough to hold the entire file, and the send buffer can hold only one percent of the file. What would prevent the process in Host A from continuously passing data to its TCP socket at rate S bps? TCP flow control? TCP congestion control? Or something else? Elaborate. (P43)}{109}{subsubsection.3.9.43}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.44}Consider sending a large file from a host to another over a TCP connection that has no loss. (P44)}{109}{subsubsection.3.9.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.45}Consider Figure 3.54. Suppose that at $t_3$, the sending rate at which congestion loss next occurs drops to $0.75 \cdot W_{\qopname  \relax m{max}}$ (unbeknownst to the TCP senders, of course). Show the evolution of both TCP Reno and TCP CUBIC for two more rounds each (Hint: note that the times at which TCP Reno and TCP CUBIC react to congestion loss may not be the same anymore). (P45)}{110}{subsubsection.3.9.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.46}Consider Figure 3.54 again. Suppose that at $t_3$, the sending rate at which congestion loss next occurs increases to $1.5 \cdot Wmax$. Show the evolution of both TCP Reno and TCP CUBIC for at two more rounds each (Hint: see the hint in P45). (P46)}{110}{subsubsection.3.9.46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.47}Recall the macroscopic description of TCP throughput. In the period of time from when the connection's rate varies from $W/(2 \cdot RTT)$ to $W/RTT$, only one packet is lost (at the very end of the period). (P47)}{110}{subsubsection.3.9.47}\protected@file@percent }
\citation{kr}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.48}Consider that only a single TCP (Reno) connection uses one 54 Mbps wireless link which does not buffer any data. Suppose that this link is the only congested link between the sending and receiving hosts. Assume that the TCP sender has a huge file to send to the receiver and the receiver's receive buffer is much larger than the congestion window. We also make the following assumptions: each TCP segment size is 536 bytes; the two-way propagation delay of this connection is 6 msec; and this TCP connection is always in congestion avoidance phase, that is, ignore slow start. (P48)}{111}{subsubsection.3.9.48}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.49}Consider the scenario described in the previous problem. Suppose that the 10 Mbps link can buffer a finite number of segments. Argue that in order for the link to always be busy sending data, we would like to choose a buffer size that is at least the product of the link speed C and the two-way propagation delay between the sender and the receiver. (P49)}{113}{subsubsection.3.9.49}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.50}Repeat Problem 48, but replacing the 54 Mbps link with a 100 Gbps link and an RTT of 60 ms. Note that in your answer to part c, you will realize that it takes a very long time for the congestion window size to reach its maximum window size after recovering from a packet loss. Can you consider solutions for this? (P50)}{113}{subsubsection.3.9.50}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.51}Let $T$ (measured by RTT) denote the time interval that a TCP connection takes to increase its congestion window size from $W/2$ to $W$, where $W$ is the maximum congestion window size. Argue that $T$ is a function of TCP's average throughput. (P51)}{113}{subsubsection.3.9.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.52}Consider a simplified TCP's AIMD algorithm where the congestion window size is measured in number of segments, not in bytes. In additive increase, the congestion window size increases by one segment in each RTT. In multiplicative decrease, the congestion window size decreases by half (if the result is not an integer, round down to the nearest integer). Suppose that two TCP connections, C1 and C2, share a single congested link of speed 30 segments per second. Assume that both C1 and C2 are in the congestion avoidance phase. Connection C1's RTT is 50 msec and connection C2's RTT is 100 msec. Assume that when the data rate in the link exceeds the link's speed, all TCP connections experience data segment loss. (P52)}{113}{subsubsection.3.9.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.53}Consider the network described in the previous problem. Now suppose that the two TCP connections, C1 and C2, have the same RTT of 100 msec. Suppose that at time $t_0$, C1's congestion window size is 15 segments but C2's congestion window size is 10 segments. (P53)}{113}{subsubsection.3.9.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.54}Consider a modification to TCP's congestion control algorithm. Instead of additive increase, we can use multiplicative increase. A TCP sender increases its window size by a small positive constant a (0 < a < 1) whenever it receives a valid ACK. Find the functional relationship between loss rate L and maximum congestion window $W$. Argue that for this modified TCP, regardless of TCP's average throughput, a TCP connection always spends the same amount of time to increase its congestion window size from $W/2$ to $W$. (P54)}{114}{subsubsection.3.9.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.55}In our discussion of TCP futures in Section 3.7, we noted that to achieve a throughput of 10 Gbps, TCP could only tolerate a segment loss probability of $2 \cdot 10^{-10}$ (or equivalently, one loss event for every 5,000,000,000 segments). Show the derivation for the values of $2 \cdot 10^{-10}$ (1 out of 5,000,000) for the RTT and MSS values given in Section 3.7. If TCP needed to support a 100 Gbps connection, what would the tolerable loss be? (P55)}{114}{subsubsection.3.9.55}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.56}In our discussion of TCP congestion control in Section 3.7, we implicitly assumed that the TCP sender always had data to send. Consider now the case that the TCP sender sends a large amount of data and then goes idle (since it has no more data to send) at $t_1$. TCP remains idle for a relatively long period of time and then wants to send more data at $t_2$. What are the advantages and disadvantages of having TCP use the cwnd and ssthresh values from t1when starting to send data at $t_2$? What alternative would you recommend? Why? (P56)}{114}{subsubsection.3.9.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.57}In this problem, we investigate whether either UDP or TCP provides a degree of end-point authentication. (P57)}{114}{subsubsection.3.9.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.9.58}In this problem, we consider the delay introduced by the TCP slow-start phase. Consider a client and a Web server directly connected by one link of rate $R$. Suppose the client wants to retrieve an object whose size is exactly equal to 15 $S$, where $S$ is the maximum segment size (MSS). Denote the round-trip time between client and server as RTT (assumed to be constant). Ignoring protocol headers, determine the time to retrieve the object (including TCP connection establishment) when: (P58)}{114}{subsubsection.3.9.58}\protected@file@percent }
\@setckpt{3_transport_layer/3.9_problems/problems}{
\setcounter{page}{115}
\setcounter{equation}{0}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{section}{3}
\setcounter{subsection}{9}
\setcounter{subsubsection}{58}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{task}{0}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{20}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{29}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{92}
\setcounter{section@level}{3}
\setcounter{lstlisting}{0}
}
